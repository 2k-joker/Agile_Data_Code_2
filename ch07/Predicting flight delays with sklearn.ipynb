{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Flight Delays with sklearn\n",
    "\n",
    "In this notebook, we will be using features we've prepared in PySpark to predict flight delays via regression and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded...\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re\n",
    "sys.path.append(\"lib\")\n",
    "import utils\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import iso8601\n",
    "import datetime\n",
    "print(\"Imports loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect our JSON Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original JSON file size: 4,096 Bytes\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '../data/simple_flight_delay_features.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-42865a3ece97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original JSON file size: {:,} Bytes\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/simple_flight_delay_features.jsonl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json_lines_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/simple_flight_delay_features.jsonl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training items: {:,}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 5,714,008\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Agile_Data_Code_2/lib/utils.py\u001b[0m in \u001b[0;36mread_json_lines_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n|\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '../data/simple_flight_delay_features.jsonl'"
     ]
    }
   ],
   "source": [
    "# Load and check the size of our training data. May take a minute.\n",
    "print(\"Original JSON file size: {:,} Bytes\".format(os.path.getsize(\"../data/simple_flight_delay_features.jsonl\")))\n",
    "\n",
    "training_data = utils.read_json_lines_file('../data/simple_flight_delay_features.jsonl')\n",
    "\n",
    "print(\"Training items: {:,}\".format(len(training_data))) # 5,714,008\n",
    "print(\"Data loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data in RAM: 406,496 Bytes\n",
      "{'ArrDelay': -14.0, 'CRSArrTime': '2015-01-01T10:25:00.000Z', 'CRSDepTime': '2015-01-01T08:55:00.000Z', 'Carrier': 'AA', 'DayOfMonth': 1, 'DayOfWeek': 4, 'DayOfYear': 1, 'DepDelay': -4.0, 'Dest': 'DFW', 'Distance': 731.0, 'FlightDate': '2015-01-01T00:00:00.000Z', 'FlightNum': '1455', 'Origin': 'ATL'}\n"
     ]
    }
   ],
   "source": [
    "# Inspect a record before we alter them\n",
    "print(\"Size of training data in RAM: {:,} Bytes\".format(sys.getsizeof(training_data))) # 50MB\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled items: 1,000,000 Bytes\n",
      "Data sampled...\n"
     ]
    }
   ],
   "source": [
    "# We need to sample our data to fit into RAM\n",
    "training_data = np.random.choice(training_data, 1000000) # 'Sample down to 1MM examples'\n",
    "print(\"Sampled items: {:,} Bytes\".format(len(training_data)))\n",
    "print(\"Data sampled...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the Results (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results vectorized size: 8,000,096\n",
      "Results vectorized...\n"
     ]
    }
   ],
   "source": [
    "# Separate our results from the rest of the data, vectorize and size up\n",
    "results = [record['ArrDelay'] for record in training_data]\n",
    "results_vector = np.array(results)\n",
    "print(\"Results vectorized size: {:,}\".format(sys.getsizeof(results_vector))) # 45,712,160 bytes\n",
    "print(\"Results vectorized...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrDelay and FlightDate removed from training data...\n"
     ]
    }
   ],
   "source": [
    "# Remove the two delay fields and the flight date from our training data\n",
    "for item in training_data:\n",
    "  item.pop('ArrDelay', None)\n",
    "  item.pop('FlightDate', None)\n",
    "print(\"ArrDelay and FlightDate removed from training data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRSArr/DepTime converted to unix time...\n"
     ]
    }
   ],
   "source": [
    "# Must convert datetime strings to unix times\n",
    "for item in training_data:\n",
    "  if isinstance(item['CRSArrTime'], str):\n",
    "    dt = iso8601.parse_date(item['CRSArrTime'])\n",
    "    unix_time = int(dt.timestamp())\n",
    "    item['CRSArrTime'] = unix_time\n",
    "  if isinstance(item['CRSDepTime'], str):\n",
    "    dt = iso8601.parse_date(item['CRSDepTime'])\n",
    "    unix_time = int(dt.timestamp())\n",
    "    item['CRSDepTime'] = unix_time\n",
    "print(\"CRSArr/DepTime converted to unix time...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Training Data with `DictVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DictVectorizer to convert feature dicts to vectors\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "print(\"Sampled dimensions: [{:,}]\".format(len(training_data)))\n",
    "vectorizer = DictVectorizer()\n",
    "training_vectors = vectorizer.fit_transform(training_data)\n",
    "print(\"Size of DictVectorized vectors: {:,} Bytes\".format(training_vectors.data.nbytes))\n",
    "print(\"Training data vectorized...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Experiment by Splitting Data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  training_vectors,\n",
    "  results_vector,\n",
    "  test_size=0.1,\n",
    "  random_state=43\n",
    ")\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(\"Test train split performed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our Model(s) on our Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a regressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "print(\"Regressor library and metrics imported...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "print(\"Regressor instantiated...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "regressor = GradientBoostingRegressor\n",
    "print(\"Swapped gradient boosting trees for linear regression!\")\n",
    "\n",
    "# Lets go back for now...\n",
    "regressor = LinearRegression()\n",
    "print(\"Swapped back to linear regression!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train)\n",
    "print(\"Regressor fitted...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = regressor.predict(X_test)\n",
    "print(\"Predictions made for X_test...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Visualize Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "\n",
    "# Median absolute error is the median of all absolute differences between the target and the prediction.\n",
    "# Less is better, more indicates a high error between target and prediction.\n",
    "medae = median_absolute_error(y_test, predicted)\n",
    "print(\"Median absolute error:    {:.3g}\".format(medae))\n",
    "\n",
    "# R2 score is the coefficient of determination. Ranges from 1-0, 1.0 is best, 0.0 is worst.\n",
    "# Measures how well future samples are likely to be predicted.\n",
    "r2 = r2_score(y_test, predicted)\n",
    "print(\"r2 score:                 {:.3g}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cleans up the appearance\n",
    "plt.rcdefaults()\n",
    "\n",
    "plt.scatter(\n",
    "  y_test,\n",
    "  predicted,\n",
    "  color='blue',\n",
    "  linewidth=1\n",
    ")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
